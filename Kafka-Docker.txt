
Features of Kubernetes
Following are some of the important features of Kubernetes.

Continues development, integration and deployment

Containerized infrastructure

Application-centric management

Auto-scalable infrastructure

Environment consistency across development testing and production

Loosely coupled infrastructure, where each component can act as a separate unit

Higher density of resource utilization

Predictable infrastructure which is going to be created




create a simple docker-compose.yml file with two services, namely zookeeper and kafka:

version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181
  
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1



start the Kafka server by spinning up the containers using the docker-compose command:
$ docker-compose up -d
Creating network "kafka_default" with the default driver
Creating kafka_zookeeper_1 ... done
Creating kafka_kafka_1     ... done


Additionally, we can also check the verbose logs while the containers are starting up and verify that the Kafka server is up:
$ docker-compose logs kafka | grep -i started
kafka_1      | [2021-04-10 22:57:40,413] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap() (kafka.controller.ZkReplicaStateMachine)
kafka_1      | [2021-04-10 22:57:40,418] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap() (kafka.controller.ZkPartitionStateMachine)
kafka_1      | [2021-04-10 22:57:40,447] INFO [SocketServer brokerId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka_1      | [2021-04-10 22:57:40,448] INFO [SocketServer brokerId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
kafka_1      | [2021-04-10 22:57:40,458] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)

https://www.baeldung.com/ops/kafka-docker-setup

//This command is used to show all the running and exited containers
docker ps -a

//command to see only runnign containers
docker ps

//This command is used to access the running container
docker exec -it <container id> bash

//to list all docker images
docker images

//to run a particular image
docker run -d -p 8000:8000  a692873757c0


//docker pull <image name>
This command is used to pull images from the docker repository(hub.docker.com)

//docker build <path to docker file>
This command is used to build an image from a specified docker file

//To go inside image container after running the image using it's id 
docker run -i -t a692873757c0 /bin/bash
docker run -i -t confluentinc/cp-kafka:7.0.1 /bin/bash
cd /bin/
ls

//To Stop the container
This command kills the container by stopping its execution immediately. The difference between ‘docker kill’ and ‘docker stop’ is that 
‘docker stop’ gives the container time to shutdown gracefully, in situations when it is taking too much time for getting the container to stop, one can opt to kill it

docker stop <container id>
docker kill image <container id>


PS C:\Users\navee> docker run -i -t confluentinc/cp-kafka:7.0.1 /bin/bash
[appuser@1f13820fa6e0 ~]$ dir
[appuser@1f13820fa6e0 ~]$ cd ..
[appuser@1f13820fa6e0 home]$ dir
appuser
[appuser@1f13820fa6e0 home]$ cd ..
[appuser@1f13820fa6e0 /]$ dir
bin  boot  dev  etc  home  lib  lib64  licenses  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var

docker stop sharp_goldberg

docker rm sharp_goldberg


****************************
1)Make a file with docker-compose.yml
version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.0.1
    container_name: broker
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

2)docker-compose up -d

3)docker ps

4)docker-compose ps

5) docker exec 813e23dded95 kafka-topics --bootstrap-server localhost:9092 --create --topic orders --partitions 1 --replication-factor 1

PS D:\Devopse> docker exec 813e23dded95 kafka-topics --bootstrap-server localhost:9092 --create --topic taxizone-topic --partitions 1 --replication-factor 1
Created topic taxizone-topic.

6)docker exec -it 813e23dded95 kafka-console-producer --bootstrap-server localhost:9092 --topic taxizone-topic

PS D:\Devopse> docker exec -it 813e23dded95 kafka-console-producer --bootstrap-server localhost:9092 --topic taxizone-topic
>hi Naveen
how are you

7) docker exec -it 813e23dded95 kafka-console-consumer --bootstrap-server localhost:9092 --topic taxizone-topic --from-beginning

PS D:\Devopse> docker exec -it 813e23dded95 kafka-console-consumer --bootstrap-server localhost:9092 --topic taxizone-topic --from-beginning
hi Naveen
how are you

